{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bucur Robert - Adrian\n",
    "# Bogdan Gheorghe - Nicolae\n",
    "## Grupa 10LF381"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laborator 6\n",
    "\n",
    "Versiunea 2020-04-01"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modele de clasificare\n",
    "\n",
    "Folositi 4 seturi de date pentru probleme de clasificare, plecand de la repository-urile specificate in Cursul 5; de exemplu, [ics.uci.edu](http://archive.ics.uci.edu/ml/datasets.php?format=mat&task=cla&att=&area=&numAtt=&numIns=&type=mvar&sort=nameUp&view=table). Cel putin doua seturi de date sa fie cu valori lipsa. \n",
    "\n",
    "\n",
    "1. (20 puncte) Aplicati o metoda de missing value imputation, unde este cazul; justificati si documentati metoda folosita.\n",
    "1. (numar de modele * numar de seturi de date \\* 1 punct = 20 de puncte) Pentru fiecare set de date aplicati 5 modele de clasificare din scikit learn. Pentru fiecare raportati: acuratete, scorul F1 - a se vedea [sklearn.metrics](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) - folosind 5 fold cross validation. Raportati mediile rezultatelor atat pentru fold-urile de antrenare, cat si pentru cele de testare. Rularile se vor face cu valori fixate ale hiperparametrilor. \n",
    "1. (numar modele * 4 puncte = 20 puncte) Documentati in jupyter notebook fiecare din modelele folosite, in limba romana. Daca acelasi algoritm e folosit pentru mai multe seturi de date, puteti face o sectiune separata cu documentarea algoritmilor + trimitere la algoritm. \n",
    "1. (numar de modele * numar de seturi de date \\* 1 punct = 20 de puncte) Pentru fiecare model: efectuati o cautare a hiperparametrilor optimi folosind grid search si random search (cu parametrul cv = 4), folosind 5 fold cross validation. \n",
    "\n",
    "Se acorda 20 de puncte din oficiu. "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemple de modele de clasificare:\n",
    "\n",
    "1. [Multi-layer Perceptron classifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier)\n",
    "1. [KNN](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier)\n",
    "1. [SVM](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC)\n",
    "1. [Gaussian processes](https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessClassifier.html#sklearn.gaussian_process.GaussianProcessClassifier)\n",
    "1. [RBF](https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.RBF.html#sklearn.gaussian_process.kernels.RBF)\n",
    "1. [Decision tree](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)\n",
    "1. [Random forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier)\n",
    "1. [Gaussian Naive bayes](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB) "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Predare:*\n",
    "\n",
    "1. Fiecare student va depune pe site-ul de elearning fisier Jupyter notebook sau arhiva cu astfel de fisiere; \n",
    "1. In fiecare fisier se specifica numele celor doi studenti care au lucra in echipa. \n",
    "1. Predarea se face in saptamana 13-17 aprilie 2020\n",
    "1. Revedeti formele ulterioare ale acestui document pentru precizari despre: continutul rezultatelor raportate, modalitate de notare."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_validate, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Folositi 4 seturi de date pentru probleme de clasificare, plecand de la repository-urile specificate in Cursul 5; de exemplu, [ics.uci.edu](http://archive.ics.uci.edu/ml/datasets.php?format=mat&task=cla&att=&area=&numAtt=&numIns=&type=mvar&sort=nameUp&view=table). Cel putin doua seturi de date sa fie cu valori lipsa."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Audit shape: (776, 17) \n\nNaN values:\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     Sector_score  PARA_A  SCORE_A  PARA_B  SCORE_B  TOTAL  numbers  Marks  \\\n642         55.57    0.23        2     0.0        2   0.23      5.0      2   \n\n     Money_Value  MONEY_Marks  District  Loss  LOSS_SCORE  History  \\\n642          NaN            2         2     0           2        0   \n\n     History_score  Score  \n642              2    2.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sector_score</th>\n      <th>PARA_A</th>\n      <th>SCORE_A</th>\n      <th>PARA_B</th>\n      <th>SCORE_B</th>\n      <th>TOTAL</th>\n      <th>numbers</th>\n      <th>Marks</th>\n      <th>Money_Value</th>\n      <th>MONEY_Marks</th>\n      <th>District</th>\n      <th>Loss</th>\n      <th>LOSS_SCORE</th>\n      <th>History</th>\n      <th>History_score</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>642</th>\n      <td>55.57</td>\n      <td>0.23</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>0.23</td>\n      <td>5.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "audit = pd.read_csv('audit_data/trial.csv', sep=';')\n",
    "print('Audit shape:', audit.shape, '\\n')\n",
    "\n",
    "X_audit = audit.iloc[:, :-1]\n",
    "y_audit = audit.iloc[:, -1]\n",
    "\n",
    "print('NaN values:')\n",
    "X_audit[X_audit.isnull().values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Banknote shape: (1372, 5) \n\nNaN values:\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [0, 1, 2, 3]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "banknote = pd.read_csv('data_banknote_authentication.csv', sep=';', header=None)\n",
    "print('Banknote shape:', banknote.shape, '\\n')\n",
    "\n",
    "X_bank = banknote.iloc[:, :-1]\n",
    "y_bank = banknote.iloc[:, -1]\n",
    "\n",
    "print('NaN values:')\n",
    "X_bank[X_bank.isnull().values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Ionosphere shape: (351, 35) \n\nNaN values:\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [0, 1, 2, 3]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "ionosphere = pd.read_csv('ionosphere.csv', sep=';', header=None)\n",
    "print('Ionosphere shape:', ionosphere.shape, '\\n')\n",
    "\n",
    "X_ionosphere = ionosphere.iloc[:, :-1]\n",
    "y_ionosphere = ionosphere.iloc[:, -1]\n",
    "\n",
    "print('NaN values:')\n",
    "X_bank[X_bank.isnull().values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercitiul 1 (20 puncte)\n",
    "Aplicati o metoda de missing value imputation, unde este cazul; justificati si documentati metoda folosita."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "imp.fit(X_audit)\n",
    "X_audit = imp.transform(X_audit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercitiul 2 (numar de modele * numar de seturi de date \\* 1 punct = 20 de puncte)\n",
    "Pentru fiecare set de date aplicati 5 modele de clasificare din scikit learn. Pentru fiecare raportati: acuratete, scorul F1 - a se vedea [sklearn.metrics](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) - folosind 5 fold cross validation. Raportati mediile rezultatelor atat pentru fold-urile de antrenare, cat si pentru cele de testare. Rularile se vor face cu valori fixate ale hiperparametrilor."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First dataset 'audit'\n",
    "## Model used: DecisionTreeClassifier"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['fit_time', 'score_time', 'test_accuracy', 'test_f1', 'train_accuracy', 'train_f1'] \n\nTrain accuracy : [1. 1. 1. 1. 1.]\nTest  accuracy : [1. 1. 1. 1. 1.]\nTrain f1       : [1. 1. 1. 1. 1.]\nTest  f1       : [1. 1. 1. 1. 1.]\n\nMean train accuaracy : 1.0\nMean test  accuaracy : 1.0\nMean train f1        : 1.0\nMean test  f1        : 1.0\n"
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(splitter='best', random_state=0, max_depth=1)\n",
    "\n",
    "scores_dtc = cross_validate(estimator=dtc, scoring=('accuracy', 'f1'), X=X_audit, y=y_audit, cv=5, return_train_score=True)\n",
    "\n",
    "print(sorted(scores_dtc.keys()), '\\n')\n",
    "\n",
    "print('Train accuracy :', scores_dtc['train_accuracy'])\n",
    "print('Test  accuracy :', scores_dtc['test_accuracy'])\n",
    "print('Train f1       :', scores_dtc['train_f1'])\n",
    "print('Test  f1       :', scores_dtc['test_f1'])\n",
    "print()\n",
    "print('Mean train accuaracy :', scores_dtc['train_accuracy'].mean())\n",
    "print('Mean test  accuaracy :', scores_dtc['test_accuracy'].mean())\n",
    "print('Mean train f1        :', scores_dtc['train_f1'].mean())\n",
    "print('Mean test  f1        :', scores_dtc['test_f1'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First dataset 'audit'\n",
    "## Model used: KNeighborsClassifier"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['fit_time', 'score_time', 'test_accuracy', 'test_f1', 'train_accuracy', 'train_f1'] \n\nTrain accuracy : [0.99032258 0.98550725 0.98550725 0.98711755 0.99194847]\nTest  accuracy : [0.97435897 0.99354839 0.79354839 0.99354839 0.40645161]\nTrain f1       : [0.99222798 0.98835705 0.98832685 0.98969072 0.99358151]\nTest  f1       : [0.98       0.99487179 0.85454545 0.99481865 0.09803922]\n\nMean train accuaracy : 0.9880806191886137\nMean test  accuaracy : 0.8322911497105047\nMean train f1        : 0.9904368228776841\nMean test  f1        : 0.784455023590653\n"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5, p=2)\n",
    "\n",
    "scores_knn = cross_validate(estimator=knn, scoring=('accuracy', 'f1'), X=X_audit, y=y_audit, cv=5, return_train_score=True)\n",
    "\n",
    "print(sorted(scores_knn.keys()), '\\n')\n",
    "\n",
    "print('Train accuracy :', scores_knn['train_accuracy'])\n",
    "print('Test  accuracy :', scores_knn['test_accuracy'])\n",
    "print('Train f1       :', scores_knn['train_f1'])\n",
    "print('Test  f1       :', scores_knn['test_f1'])\n",
    "print()\n",
    "print('Mean train accuaracy :', scores_knn['train_accuracy'].mean())\n",
    "print('Mean test  accuaracy :', scores_knn['test_accuracy'].mean())\n",
    "print('Mean train f1        :', scores_knn['train_f1'].mean())\n",
    "print('Mean test  f1        :', scores_knn['test_f1'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First dataset 'audit'\n",
    "## Model used: SVM.SVC"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "SVC model\n\n['fit_time', 'score_time', 'test_accuracy', 'test_f1', 'train_accuracy', 'train_f1'] \n\nTrain accuracy : [1.         1.         1.         0.99838969 1.        ]\nTest  accuracy : [0.96794872 0.99354839 0.81290323 0.96774194 0.65806452]\nTrain f1       : [1.       1.       1.       0.998713 1.      ]\nTest  f1       : [0.97512438 0.99487179 0.86995516 0.97354497 0.62411348]\n\nMean train accuaracy : 0.9996779388083736\nMean test  accuaracy : 0.8800413564929693\nMean train f1        : 0.9997425997425997\nMean test  f1        : 0.8875219557308398\n"
    }
   ],
   "source": [
    "svc = SVC(C=1.0, gamma='auto')\n",
    "\n",
    "scores_svc = cross_validate(estimator=svc, scoring=('accuracy', 'f1'), X=X_audit, y=y_audit, cv=5, return_train_score=True)\n",
    "\n",
    "print('SVC model\\n')\n",
    "\n",
    "print(sorted(scores_svc.keys()), '\\n')\n",
    "\n",
    "print('Train accuracy :', scores_svc['train_accuracy'])\n",
    "print('Test  accuracy :', scores_svc['test_accuracy'])\n",
    "print('Train f1       :', scores_svc['train_f1'])\n",
    "print('Test  f1       :', scores_svc['test_f1'])\n",
    "print()\n",
    "print('Mean train accuaracy :', scores_svc['train_accuracy'].mean())\n",
    "print('Mean test  accuaracy :', scores_svc['test_accuracy'].mean())\n",
    "print('Mean train f1        :', scores_svc['train_f1'].mean())\n",
    "print('Mean test  f1        :', scores_svc['test_f1'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First dataset 'audit'\n",
    "## Model used: GaussianProcessClassifier"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['fit_time', 'score_time', 'test_accuracy', 'test_f1', 'train_accuracy', 'train_f1']\n\nTrain accuracy : [1. 1. 1. 1. 1.]\nTest  accuracy : [0.95512821 0.95483871 0.79354839 0.98709677 0.37419355]\nTrain f1       : [1. 1. 1. 1. 1.]\nTest  f1       : [0.96446701 0.96296296 0.85454545 0.98958333 0.        ]\n\nMean train accuracy : 1.0\nMean test  accuracy : 0.8129611248966088\nMean train f1       : 1.0\nMean test f1        : 0.7543117511835785\n"
    }
   ],
   "source": [
    "gpc = GaussianProcessClassifier(random_state=0)\n",
    "\n",
    "scores_gpc = cross_validate(estimator=gpc, scoring=('accuracy', 'f1'), X=X_audit, y=y_audit, cv=5, return_train_score=True)\n",
    "\n",
    "print(sorted(scores_gpc.keys()))\n",
    "print()\n",
    "print('Train accuracy :', scores_gpc['train_accuracy'])\n",
    "print('Test  accuracy :', scores_gpc['test_accuracy'])\n",
    "print('Train f1       :', scores_gpc['train_f1'])\n",
    "print('Test  f1       :', scores_gpc['test_f1'])\n",
    "print()\n",
    "print('Mean train accuracy :', scores_gpc['train_accuracy'].mean())\n",
    "print('Mean test  accuracy :', scores_gpc['test_accuracy'].mean())\n",
    "print('Mean train f1       :', scores_gpc['train_f1'].mean())\n",
    "print('Mean test f1        :', scores_gpc['test_f1'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First dataset 'audit'\n",
    "## Model used: RandomForestClassifier"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['fit_time', 'score_time', 'test_accuracy', 'test_f1', 'train_accuracy', 'train_f1']\n\nTrain accuracy      : [1. 1. 1. 1. 1.]\nTest  accuracy      : [1.         1.         1.         1.         0.97419355]\nTrain f1            : [1. 1. 1. 1. 1.]\nTest  f1            : [1.         1.         1.         1.         0.97894737]\n\nMean train accuracy : 1.0\nMean test  accuracy : 0.9948387096774194\nMean train f1       : 1.0\nMean test f1        : 0.9957894736842106\n"
    }
   ],
   "source": [
    "rcf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "\n",
    "scores_rcf = cross_validate(estimator=rcf, scoring=('accuracy', 'f1'), X=X_audit, y=y_audit, cv=5, return_train_score=True)\n",
    "\n",
    "print(sorted(scores_rcf.keys()))\n",
    "print()\n",
    "print('Train accuracy      :', scores_rcf['train_accuracy'])\n",
    "print('Test  accuracy      :', scores_rcf['test_accuracy'])\n",
    "print('Train f1            :', scores_rcf['train_f1'])\n",
    "print('Test  f1            :', scores_rcf['test_f1'])\n",
    "print()\n",
    "print('Mean train accuracy :', scores_rcf['train_accuracy'].mean())\n",
    "print('Mean test  accuracy :', scores_rcf['test_accuracy'].mean())\n",
    "print('Mean train f1       :', scores_rcf['train_f1'].mean())\n",
    "print('Mean test f1        :', scores_rcf['test_f1'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second dataset 'banknote'\n",
    "## Model used: DecisionTreeClassifier"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Decision Tree Classifier model\n\n['fit_time', 'score_time', 'test_accuracy', 'test_f1', 'train_accuracy', 'train_f1'] \n\nTrain accuracy : [1. 1. 1. 1. 1.]\nTest  accuracy : [0.99272727 0.98545455 0.98540146 0.99635036 0.97445255]\nTrain f1       : [1. 1. 1. 1. 1.]\nTest  f1       : [0.99186992 0.98373984 0.98373984 0.99591837 0.97142857]\n\nMean train accuaracy : 1.0\nMean test  accuaracy : 0.9868772395487723\nMean train f1        : 1.0\nMean test  f1        : 0.985339306454289\n"
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(splitter='random', random_state=0)\n",
    "\n",
    "scores_dtc = cross_validate(estimator=dtc, scoring=('accuracy', 'f1'), X=X_bank, y=y_bank, cv=5, return_train_score=True)\n",
    "\n",
    "print('Decision Tree Classifier model\\n')\n",
    "\n",
    "print(sorted(scores_dtc.keys()), '\\n')\n",
    "\n",
    "print('Train accuracy :', scores_dtc['train_accuracy'])\n",
    "print('Test  accuracy :', scores_dtc['test_accuracy'])\n",
    "print('Train f1       :', scores_dtc['train_f1'])\n",
    "print('Test  f1       :', scores_dtc['test_f1'])\n",
    "print()\n",
    "print('Mean train accuaracy :', scores_dtc['train_accuracy'].mean())\n",
    "print('Mean test  accuaracy :', scores_dtc['test_accuracy'].mean())\n",
    "print('Mean train f1        :', scores_dtc['train_f1'].mean())\n",
    "print('Mean test  f1        :', scores_dtc['test_f1'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second dataset 'banknote'\n",
    "## Model used: KNeighborsClassifier"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "K Nearest Neighbors model\n\n['fit_time', 'score_time', 'test_accuracy', 'test_f1', 'train_accuracy', 'train_f1'] \n\nTrain accuracy : [0.99544211 0.99453054 0.99635701 0.99453552 0.99726776]\nTest  accuracy : [0.99636364 1.         0.99270073 1.         0.98905109]\nTrain f1       : [0.99488229 0.99386503 0.99591837 0.99386503 0.99692308]\nTest  f1       : [0.99591837 1.         0.99173554 1.         0.98785425]\n\nMean train accuaracy : 0.9956265888256265\nMean test  accuaracy : 0.9956230922362309\nMean train f1        : 0.9950907596705129\nMean test  f1        : 0.9951016311098334\n"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5, p=2)\n",
    "\n",
    "scores_knn = cross_validate(estimator=knn, scoring=('accuracy', 'f1'), X=X_bank, y=y_bank, cv=5, return_train_score=True)\n",
    "\n",
    "print('K Nearest Neighbors model\\n')\n",
    "\n",
    "print(sorted(scores_knn.keys()), '\\n')\n",
    "\n",
    "print('Train accuracy :', scores_knn['train_accuracy'])\n",
    "print('Test  accuracy :', scores_knn['test_accuracy'])\n",
    "print('Train f1       :', scores_knn['train_f1'])\n",
    "print('Test  f1       :', scores_knn['test_f1'])\n",
    "print()\n",
    "print('Mean train accuaracy :', scores_knn['train_accuracy'].mean())\n",
    "print('Mean test  accuaracy :', scores_knn['test_accuracy'].mean())\n",
    "print('Mean train f1        :', scores_knn['train_f1'].mean())\n",
    "print('Mean test  f1        :', scores_knn['test_f1'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second dataset 'banknote'\n",
    "## Model used: SVM.SVC"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "SVC model\n\n['fit_time', 'score_time', 'test_accuracy', 'test_f1', 'train_accuracy', 'train_f1'] \n\nTrain accuracy : [1. 1. 1. 1. 1.]\nTest  accuracy : [1.         0.99636364 0.99270073 1.         1.        ]\nTrain f1       : [1. 1. 1. 1. 1.]\nTest  f1       : [1.         0.99588477 0.99173554 1.         1.        ]\n\nMean train accuaracy : 1.0\nMean test  accuaracy : 0.9978128732581286\nMean train f1        : 1.0\nMean test  f1        : 0.9975240621705268\n"
    }
   ],
   "source": [
    "svc = SVC(C=1.0, gamma='auto')\n",
    "\n",
    "scores_svc = cross_validate(estimator=svc, scoring=('accuracy', 'f1'), X=X_bank, y=y_bank, cv=5, return_train_score=True)\n",
    "\n",
    "print('SVC model\\n')\n",
    "\n",
    "print(sorted(scores_svc.keys()), '\\n')\n",
    "\n",
    "print('Train accuracy :', scores_svc['train_accuracy'])\n",
    "print('Test  accuracy :', scores_svc['test_accuracy'])\n",
    "print('Train f1       :', scores_svc['train_f1'])\n",
    "print('Test  f1       :', scores_svc['test_f1'])\n",
    "print()\n",
    "print('Mean train accuaracy :', scores_svc['train_accuracy'].mean())\n",
    "print('Mean test  accuaracy :', scores_svc['test_accuracy'].mean())\n",
    "print('Mean train f1        :', scores_svc['train_f1'].mean())\n",
    "print('Mean test  f1        :', scores_svc['test_f1'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second dataset 'banknote'\n",
    "## Model used: GaussianProcessClassifier"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['fit_time', 'score_time', 'test_accuracy', 'test_f1', 'train_accuracy', 'train_f1']\n\nTrain accuracy : [1. 1. 1. 1. 1.]\nTest  accuracy : [1.         0.99636364 0.99270073 0.99635036 1.        ]\nTrain f1       : [1. 1. 1. 1. 1.]\nTest  f1       : [1.         0.99588477 0.99173554 0.99591837 1.        ]\n\nMean train accuracy : 1.0\nMean test  accuracy : 0.9970829462508295\nMean train f1       : 1.0\nMean test f1        : 0.9967077356399144\n"
    }
   ],
   "source": [
    "gpc = GaussianProcessClassifier(random_state=0)\n",
    "\n",
    "scores_gpc = cross_validate(estimator=gpc, scoring=('accuracy', 'f1'), X=X_bank, y=y_bank, cv=5, return_train_score=True)\n",
    "\n",
    "print(sorted(scores_gpc.keys()))\n",
    "print()\n",
    "print('Train accuracy :', scores_gpc['train_accuracy'])\n",
    "print('Test  accuracy :', scores_gpc['test_accuracy'])\n",
    "print('Train f1       :', scores_gpc['train_f1'])\n",
    "print('Test  f1       :', scores_gpc['test_f1'])\n",
    "print()\n",
    "print('Mean train accuracy :', scores_gpc['train_accuracy'].mean())\n",
    "print('Mean test  accuracy :', scores_gpc['test_accuracy'].mean())\n",
    "print('Mean train f1       :', scores_gpc['train_f1'].mean())\n",
    "print('Mean test f1        :', scores_gpc['test_f1'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second dataset 'banknote'\n",
    "## Model used: RandomForestClassifier"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['fit_time', 'score_time', 'test_accuracy', 'test_f1', 'train_accuracy', 'train_f1']\n\nTrain accuracy      : [0.89243391 0.89881495 0.89617486 0.89162113 0.89435337]\nTest  accuracy      : [0.90181818 0.87272727 0.88686131 0.90875912 0.89781022]\nTrain f1            : [0.8691796  0.87734807 0.87417219 0.86792453 0.87168142]\nTest  f1            : [0.88105727 0.84304933 0.86098655 0.89082969 0.87610619]\n\nMean train accuracy : 0.8946796446011891\nMean test  accuracy : 0.8935952222959521\nMean train f1       : 0.8720611593693629\nMean test f1        : 0.8704058064350676\n"
    }
   ],
   "source": [
    "rcf = RandomForestClassifier(max_depth=1, random_state=0)\n",
    "\n",
    "scores_rcf = cross_validate(estimator=rcf, scoring=('accuracy', 'f1'), X=X_bank, y=y_bank, cv=5, return_train_score=True)\n",
    "\n",
    "print(sorted(scores_rcf.keys()))\n",
    "print()\n",
    "print('Train accuracy      :', scores_rcf['train_accuracy'])\n",
    "print('Test  accuracy      :', scores_rcf['test_accuracy'])\n",
    "print('Train f1            :', scores_rcf['train_f1'])\n",
    "print('Test  f1            :', scores_rcf['test_f1'])\n",
    "print()\n",
    "print('Mean train accuracy :', scores_rcf['train_accuracy'].mean())\n",
    "print('Mean test  accuracy :', scores_rcf['test_accuracy'].mean())\n",
    "print('Mean train f1       :', scores_rcf['train_f1'].mean())\n",
    "print('Mean test f1        :', scores_rcf['test_f1'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercitiul 3 (numar modele * 4 puncte = 20 puncte)\n",
    "Documentati in jupyter notebook fiecare din modelele folosite, in limba romana. Daca acelasi algoritm e folosit pentru mai multe seturi de date, puteti face o sectiune separata cu documentarea algoritmilor + trimitere la algoritm. "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercitiul 4 (numar de modele * numar de seturi de date \\* 1 punct = 20 de puncte)\n",
    "Pentru fiecare model: efectuati o cautare a hiperparametrilor optimi folosind grid search si random search (cu parametrul cv = 4), folosind 5 fold cross validation."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'n_neighbors': 9, 'p': 1}\n0.8374441687344912\n{'p': 3, 'n_neighbors': 1}\n0.8374524400330852\n"
    }
   ],
   "source": [
    "parameter_grid = {'n_neighbors': list(range(1, 10)), 'p': [1, 2, 3, 4.7]}\n",
    "grid_search = GridSearchCV(estimator=knn, param_grid=parameter_grid, scoring='accuracy', cv=4)\n",
    "grid_search.fit(X_audit, y_audit)\n",
    "grid_scores = cross_val_score(grid_search, X_audit, y_audit, cv=5)\n",
    "print(grid_search.best_params_)\n",
    "print(grid_scores.mean())\n",
    "\n",
    "randomized_search = RandomizedSearchCV(knn, parameter_grid, random_state=0, scoring='accuracy')\n",
    "randomized_search.fit(X_audit, y_audit)\n",
    "randomized_scores = cross_val_score(randomized_search, X_audit, y_audit, cv=5)\n",
    "print(randomized_search.best_params_)\n",
    "print(randomized_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C=1.0, gamma='auto'\n",
    "# parameter_grid = {'C': list(range(1, 10)), 'p': [1, 2, 3, 4.7]}\n",
    "# grid_search = GridSearchCV(estimator=svc, param_grid=parameter_grid, scoring='accuracy', cv=4)\n",
    "# grid_search.fit(X_audit, y_audit)\n",
    "# scores = cross_val_score(grid_search, X_audit, y_audit, cv=5)\n",
    "# print(grid_search.best_params_)\n",
    "# print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}